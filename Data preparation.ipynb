{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8db2bf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+--------+---------+----------------+-------+\n",
      "|magnitude|  depth|latitude|longitude|       date_time|tsunami|\n",
      "+---------+-------+--------+---------+----------------+-------+\n",
      "|      7.0|   14.0| -9.7963|  159.596|22-11-2022 02:03|      1|\n",
      "|      6.9|   25.0| -4.9559|  100.738|18-11-2022 13:37|      0|\n",
      "|      7.0|  579.0|-20.0508| -178.346|12-11-2022 07:09|      1|\n",
      "|      7.3|   37.0|-19.2918| -172.129|11-11-2022 10:48|      1|\n",
      "|      6.6|624.464|-25.5948|  178.278|09-11-2022 10:14|      1|\n",
      "|      7.0|  660.0|-26.0442|  178.381|09-11-2022 09:51|      1|\n",
      "|      6.8|630.379|-25.9678|  178.363|09-11-2022 09:38|      1|\n",
      "|      6.7|   20.0|  7.6712| -82.3396|20-10-2022 11:57|      1|\n",
      "|      6.8|   20.0|   18.33| -102.913|22-09-2022 06:16|      1|\n",
      "|      7.6| 26.943| 18.3667| -103.252|19-09-2022 18:05|      1|\n",
      "|      6.9|   10.0| 23.1444|  121.307|18-09-2022 06:44|      1|\n",
      "|      6.5|   10.0|  23.029|  121.348|17-09-2022 13:41|      1|\n",
      "|      7.0|  137.0|-21.2077|  170.239|14-09-2022 11:04|      1|\n",
      "|      7.6|  116.0| -6.2237|  146.471|10-09-2022 23:47|      1|\n",
      "|      6.6|   12.0| 29.7263|  102.279|05-09-2022 04:52|      0|\n",
      "|      6.6|   30.0|-32.6922| -178.959|14-08-2022 13:44|      1|\n",
      "|      7.0| 33.729| 17.5978|  120.809|27-07-2022 00:43|      1|\n",
      "|      6.5| 622.73| -9.0618| -71.1647|08-06-2022 00:55|      0|\n",
      "|      7.2|  236.0|-14.8628| -70.3081|26-05-2022 12:02|      1|\n",
      "|      6.9|   10.0|-54.1325|  159.027|19-05-2022 10:13|      1|\n",
      "+---------+-------+--------+---------+----------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-3.2.1-bin-hadoop2.7')\n",
    "\n",
    "import pyspark \n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('basics').getOrCreate()\n",
    "\n",
    "file_path = 'Dataset/earthquake_data.csv'\n",
    "earthquake_data = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Selecting the desired columns\n",
    "selected_columns = ['magnitude', 'depth', 'latitude', 'longitude','date_time','tsunami']\n",
    "selected_data = earthquake_data.select(selected_columns)\n",
    "\n",
    "# Display the top rows of the selected data\n",
    "selected_data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d49729b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+------------------+-------+--------------+--------+---------+\n",
      "|       date_time|magnitude|Magnitude Category|  depth|Depth Category|latitude|longitude|\n",
      "+----------------+---------+------------------+-------+--------------+--------+---------+\n",
      "|22-11-2022 02:03|      7.0|             Major|   14.0|       Shallow| -9.7963|  159.596|\n",
      "|18-11-2022 13:37|      6.9|            Strong|   25.0|       Shallow| -4.9559|  100.738|\n",
      "|12-11-2022 07:09|      7.0|             Major|  579.0|          Deep|-20.0508| -178.346|\n",
      "|11-11-2022 10:48|      7.3|             Major|   37.0|       Shallow|-19.2918| -172.129|\n",
      "|09-11-2022 10:14|      6.6|            Strong|624.464|          Deep|-25.5948|  178.278|\n",
      "|09-11-2022 09:51|      7.0|             Major|  660.0|          Deep|-26.0442|  178.381|\n",
      "|09-11-2022 09:38|      6.8|            Strong|630.379|          Deep|-25.9678|  178.363|\n",
      "|20-10-2022 11:57|      6.7|            Strong|   20.0|       Shallow|  7.6712| -82.3396|\n",
      "|22-09-2022 06:16|      6.8|            Strong|   20.0|       Shallow|   18.33| -102.913|\n",
      "|19-09-2022 18:05|      7.6|             Major| 26.943|       Shallow| 18.3667| -103.252|\n",
      "|18-09-2022 06:44|      6.9|            Strong|   10.0|       Shallow| 23.1444|  121.307|\n",
      "|17-09-2022 13:41|      6.5|            Strong|   10.0|       Shallow|  23.029|  121.348|\n",
      "|14-09-2022 11:04|      7.0|             Major|  137.0|  Intermediate|-21.2077|  170.239|\n",
      "|10-09-2022 23:47|      7.6|             Major|  116.0|  Intermediate| -6.2237|  146.471|\n",
      "|05-09-2022 04:52|      6.6|            Strong|   12.0|       Shallow| 29.7263|  102.279|\n",
      "|14-08-2022 13:44|      6.6|            Strong|   30.0|       Shallow|-32.6922| -178.959|\n",
      "|27-07-2022 00:43|      7.0|             Major| 33.729|       Shallow| 17.5978|  120.809|\n",
      "|08-06-2022 00:55|      6.5|            Strong| 622.73|          Deep| -9.0618| -71.1647|\n",
      "|26-05-2022 12:02|      7.2|             Major|  236.0|  Intermediate|-14.8628| -70.3081|\n",
      "|19-05-2022 10:13|      6.9|            Strong|   10.0|       Shallow|-54.1325|  159.027|\n",
      "+----------------+---------+------------------+-------+--------------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Initialize SparkSession (assuming it's already done)\n",
    "# spark = SparkSession.builder.appName('basics').getOrCreate()\n",
    "\n",
    "# Assuming 'selected_data' is already a PySpark DataFrame\n",
    "\n",
    "# Define the UDFs for Magnitude and Depth categories\n",
    "@udf(StringType())\n",
    "def magnitude_category(magnitude):\n",
    "    if magnitude < 5:\n",
    "        return \"Light\"\n",
    "    elif 5 <= magnitude < 6:\n",
    "        return \"Moderate\"\n",
    "    elif 6 <= magnitude < 7:\n",
    "        return \"Strong\"\n",
    "    elif 7 <= magnitude < 8:\n",
    "        return \"Major\"\n",
    "    else:\n",
    "        return \"Great\"\n",
    "\n",
    "@udf(StringType())\n",
    "def depth_category(depth):\n",
    "    if depth < 70:\n",
    "        return \"Shallow\"\n",
    "    elif 70 <= depth < 300:\n",
    "        return \"Intermediate\"\n",
    "    else:\n",
    "        return \"Deep\"\n",
    "\n",
    "# Apply the UDFs to create the new columns\n",
    "selected_data = selected_data.withColumn('Magnitude Category', magnitude_category(selected_data['magnitude']))\n",
    "selected_data = selected_data.withColumn('Depth Category', depth_category(selected_data['depth']))\n",
    "\n",
    "# Show the top rows with the new columns\n",
    "selected_data.select('date_time', 'magnitude', 'Magnitude Category', 'depth', 'Depth Category', 'latitude', 'longitude').show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f05d1d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+-------+--------+---------+-------+------------------+--------------+----------------------------+-------------+--------------------+\n",
      "|       date_time|magnitude|  depth|latitude|longitude|tsunami|Magnitude Category|Depth Category|number_of_buildings_impacted|economic_loss|            location|\n",
      "+----------------+---------+-------+--------+---------+-------+------------------+--------------+----------------------------+-------------+--------------------+\n",
      "|22-11-2022 02:03|      7.0|   14.0| -9.7963|  159.596|      1|             Major|       Shallow|                        1502|     10790000|    Malango, Islands|\n",
      "|18-11-2022 13:37|      6.9|   25.0| -4.9559|  100.738|      0|            Strong|       Shallow|                        2587|     28900000| Bengkulu, Indonesia|\n",
      "|12-11-2022 07:09|      7.0|  579.0|-20.0508| -178.346|      1|             Major|          Deep|                        2654|     23040000|                null|\n",
      "|11-11-2022 10:48|      7.3|   37.0|-19.2918| -172.129|      1|             Major|       Shallow|                        1056|     23020000|       Neiafu, Tonga|\n",
      "|09-11-2022 10:14|      6.6|624.464|-25.5948|  178.278|      1|            Strong|          Deep|                         706|      1080000|                null|\n",
      "|09-11-2022 09:51|      7.0|  660.0|-26.0442|  178.381|      1|             Major|          Deep|                         107|     40270000|   the Fiji, Islands|\n",
      "|09-11-2022 09:38|      6.8|630.379|-25.9678|  178.363|      1|            Strong|          Deep|                         590|     41340000|   the Fiji, Islands|\n",
      "|20-10-2022 11:57|      6.7|   20.0|  7.6712| -82.3396|      1|            Strong|       Shallow|                        2469|     32070000|  Boca Chica, Panama|\n",
      "|22-09-2022 06:16|      6.8|   20.0|   18.33| -102.913|      1|            Strong|       Shallow|                        2414|     11840000|   Aguililla, Mexico|\n",
      "|19-09-2022 18:05|      7.6| 26.943| 18.3667| -103.252|      1|             Major|       Shallow|                        1601|     38320000|   Aguililla, Mexico|\n",
      "|18-09-2022 06:44|      6.9|   10.0| 23.1444|  121.307|      1|            Strong|       Shallow|                        2465|      3190000|      Yujing, Taiwan|\n",
      "|17-09-2022 13:41|      6.5|   10.0|  23.029|  121.348|      1|            Strong|       Shallow|                         229|     34900000|        Lugu, Taiwan|\n",
      "|14-09-2022 11:04|      7.0|  137.0|-21.2077|  170.239|      1|             Major|  Intermediate|                         916|     32800000|    Isangel, Vanuatu|\n",
      "|10-09-2022 23:47|      7.6|  116.0| -6.2237|  146.471|      1|             Major|  Intermediate|                         795|      6070000|    Kainantu, Guinea|\n",
      "|05-09-2022 04:52|      6.6|   12.0| 29.7263|  102.279|      0|            Strong|       Shallow|                        3022|     20940000|     Kangding, China|\n",
      "|14-08-2022 13:44|      6.6|   30.0|-32.6922| -178.959|      1|            Strong|       Shallow|                        3544|     19750000|the Kermadec, Isl...|\n",
      "|27-07-2022 00:43|      7.0| 33.729| 17.5978|  120.809|      1|             Major|       Shallow|                        1074|     43770000| Bantay, Philippines|\n",
      "|08-06-2022 00:55|      6.5| 622.73| -9.0618| -71.1647|      0|            Strong|          Deep|                        3352|     23710000|    Tarauacá, Brazil|\n",
      "|26-05-2022 12:02|      7.2|  236.0|-14.8628| -70.3081|      1|             Major|  Intermediate|                        1745|     13770000|      Azángaro, Peru|\n",
      "|19-05-2022 10:13|      6.9|   10.0|-54.1325|  159.027|      1|            Strong|       Shallow|                        1085|     41250000|                null|\n",
      "+----------------+---------+-------+--------+---------+-------+------------------+--------------+----------------------------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the infrastructure_damage data from CSV\n",
    "infrastructure_damage = spark.read.csv('Dataset/infrastructure_damage.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Join the two dataframes on the 'date_time' column\n",
    "merged_df = selected_data.join(infrastructure_damage, on='date_time', how='inner')\n",
    "# Drop the unwanted columns\n",
    "merged_ds = merged_df.drop(\"Unnamed: 4\", \"Unnamed: 5\")\n",
    "\n",
    "# Display the merged data\n",
    "merged_ds.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07dd1427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+--------+---------+----------------+----------------------------+-------------+\n",
      "|magnitude|  depth|latitude|longitude|       date_time|number_of_buildings_impacted|economic_loss|\n",
      "+---------+-------+--------+---------+----------------+----------------------------+-------------+\n",
      "|      7.0|   14.0| -9.7963|  159.596|22-11-2022 02:03|                        1502|     10790000|\n",
      "|      6.9|   25.0| -4.9559|  100.738|18-11-2022 13:37|                        2587|     28900000|\n",
      "|      7.0|  579.0|-20.0508| -178.346|12-11-2022 07:09|                        2654|     23040000|\n",
      "|      7.3|   37.0|-19.2918| -172.129|11-11-2022 10:48|                        1056|     23020000|\n",
      "|      6.6|624.464|-25.5948|  178.278|09-11-2022 10:14|                         706|      1080000|\n",
      "|      7.0|  660.0|-26.0442|  178.381|09-11-2022 09:51|                         107|     40270000|\n",
      "|      6.8|630.379|-25.9678|  178.363|09-11-2022 09:38|                         590|     41340000|\n",
      "|      6.7|   20.0|  7.6712| -82.3396|20-10-2022 11:57|                        2469|     32070000|\n",
      "|      6.8|   20.0|   18.33| -102.913|22-09-2022 06:16|                        2414|     11840000|\n",
      "|      7.6| 26.943| 18.3667| -103.252|19-09-2022 18:05|                        1601|     38320000|\n",
      "|      6.9|   10.0| 23.1444|  121.307|18-09-2022 06:44|                        2465|      3190000|\n",
      "|      6.5|   10.0|  23.029|  121.348|17-09-2022 13:41|                         229|     34900000|\n",
      "|      7.0|  137.0|-21.2077|  170.239|14-09-2022 11:04|                         916|     32800000|\n",
      "|      7.6|  116.0| -6.2237|  146.471|10-09-2022 23:47|                         795|      6070000|\n",
      "|      6.6|   12.0| 29.7263|  102.279|05-09-2022 04:52|                        3022|     20940000|\n",
      "|      6.6|   30.0|-32.6922| -178.959|14-08-2022 13:44|                        3544|     19750000|\n",
      "|      7.0| 33.729| 17.5978|  120.809|27-07-2022 00:43|                        1074|     43770000|\n",
      "|      6.5| 622.73| -9.0618| -71.1647|08-06-2022 00:55|                        3352|     23710000|\n",
      "|      7.2|  236.0|-14.8628| -70.3081|26-05-2022 12:02|                        1745|     13770000|\n",
      "|      6.9|   10.0|-54.1325|  159.027|19-05-2022 10:13|                        1085|     41250000|\n",
      "+---------+-------+--------+---------+----------------+----------------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify the columns you want to select\n",
    "selected_columns = ['magnitude', 'depth', 'latitude', \n",
    "                    'longitude', 'date_time', \n",
    "                    'number_of_buildings_impacted', \n",
    "                    'economic_loss']\n",
    "\n",
    "# Select the desired columns from the merged DataFrame\n",
    "reduced_data = merged_ds.select(*selected_columns)\n",
    "\n",
    "# Display the reduced data\n",
    "reduced_data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "553f8d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path where you want to save the data\n",
    "output_path = \"BDAS/Dataset\"\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "reduced_data.write.csv(output_path, header=True, mode=\"overwrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d987c12c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/data/merged_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/mnt/data/merged_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Extract and standardize the numerical columns\u001b[39;00m\n\u001b[1;32m      7\u001b[0m numerical_data \u001b[38;5;241m=\u001b[39m df[numerical_features]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/data/merged_data.csv'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2aa083",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
